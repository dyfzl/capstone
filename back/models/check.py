import pandas as pd
import re
import unicodedata
import logging

logging.basicConfig(level=logging.INFO)

def merge_feedback_with_train_data(train_data_path, feedback_data_path):
    train_data = pd.read_csv(train_data_path)
    feedback_data = pd.read_csv(feedback_data_path)
    merged_data = pd.concat([train_data, feedback_data], ignore_index=True)
    return merged_data

# ì´ëª¨í‹°ì½˜ ë§¤í•‘
EMOTICON_MAP = {
    "â¤ï¸": "ì‚¬ë‘í•´ìš”", "ğŸ§¡": "ì‚¬ë‘í•´ìš”", "ğŸ’›": "ì‚¬ë‘í•´ìš”", "ğŸ’š": "ì‚¬ë‘í•´ìš”",
    "ğŸ’™": "ì‚¬ë‘í•´ìš”", "ğŸ’": "ì‚¬ë‘í•´ìš”", "ğŸ’“": "ì‚¬ë‘í•´ìš”", "ğŸ’œ": "ì‚¬ë‘í•´ìš”",
    "â£ï¸": "ì‚¬ë‘í•´ìš”", "ğŸ’•": "ì‚¬ë‘í•´ìš”", "ğŸ’˜": "ì‚¬ë‘í•´ìš”", "ğŸ’—": "ì‚¬ë‘í•´ìš”",
    "ğŸ’": "ì‚¬ë‘í•´ìš”", "ğŸ’Ÿ": "ì‚¬ë‘í•´ìš”", "ğŸ˜»": "ì‚¬ë‘í•´ìš”", "ğŸ’”": "ì‹«ì–´í•´ìš”",
    "ğŸ‘": "ìµœê³ ì—ìš”", "ğŸ‘": "ìµœì•…ì´ì—ìš”", "ğŸ™Œ": "ë§Œì„¸", "ğŸ˜˜": "ì‚¬ë‘í•´ìš”",
    "ğŸ˜": "ì‚¬ë‘í•´ìš”", "ğŸ˜ƒ": "ì¢‹ì•„ìš”", "ğŸ˜„": "ì¢‹ì•„ìš”", "ğŸ˜": "ì¢‹ì•„ìš”",
    "ğŸ˜†": "ì¢‹ì•„ìš”", "â˜ºï¸": "ì¢‹ì•„ìš”", "ğŸ˜Š": "ì¢‹ì•„ìš”", "ğŸ˜š": "ì¢‹ì•„ìš”",
    "ğŸ¤—": "ì¢‹ì•„ìš”", "ğŸ˜­": "ìŠ¬í¼ìš”", "ğŸ˜¢": "ìŠ¬í¼ìš”", "ğŸ˜¤": "ì‚ì¡Œì–´ìš”",
    "ğŸ˜ ": "í™”ë‚¬ì–´ìš”", "ğŸ˜¡": "í™”ë‚¬ì–´ìš”", "ğŸ¤¬": "í™”ë‚¬ì–´ìš”", "ğŸ˜³": "ì˜ ëª¨ë¥´ê² ì–´ìš”",
    "ğŸ¤”": "ê³ ë¯¼í•´ ë³¼ê²Œìš”", "^^": "ì¢‹ì•„ìš”", "â™¡": "ì‚¬ë‘í•´ìš”", "â™¥": "ì‚¬ë‘í•´ìš”"
}

# ì´ëª¨í‹°ì½˜ ì²˜ë¦¬ í•¨ìˆ˜
def replace_emoticons(text):
    """
    Replace emoticons and special symbols in text with mapped expressions.
    Handles non-string types by converting them to strings.
    """
    if not isinstance(text, str):  # ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
        return str(text)  # ë¬¸ìì—´ë¡œ ë³€í™˜
    
    # ì •ê·œì‹ íŒ¨í„´ ìƒì„±
    pattern = re.compile("|".join(re.escape(k) for k in EMOTICON_MAP.keys()))
    return pattern.sub(lambda m: EMOTICON_MAP[m.group(0)], text)

def remove_special_characters(text):
    """
    Remove special characters except !, ?, ., ,. Also removes newlines (\n).
    """
    # \n í¬í•¨í•˜ì—¬ ì œê±°
    return re.sub(r'[^!?.,\w\s]', '', text).replace('\n', '')



# ìëª¨ ë¶„ë¦¬ í•´ê²° ë° ì¤‘ë³µ ë¬¸ì ì •ë¦¬ í•¨ìˆ˜
def preprocess_text(text):
    """
    Normalize text to resolve Jamo separation and reduce repeated characters.
    """
    # ìëª¨ ë¶„ë¦¬ í•´ê²°
    text = unicodedata.normalize('NFC', text)
    # ì¤‘ë³µ ë¬¸ì ì •ë¦¬ (3íšŒ ì´ìƒ ë°˜ë³µë˜ëŠ” ë¬¸ì 2íšŒë¡œ ì¶•ì†Œ)
    text = re.sub(r"(.)\1{2,}", r"\1\1", text)
    return text

# ë°ì´í„°í”„ë ˆì„ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_dataframe(df, text_column='comment'):
    """
    Preprocess a DataFrame by handling NaN, stripping whitespace, replacing emoticons,
    removing special characters, and normalizing text.
    Filters rows based on text length (5 to 300 characters).
    """
    if text_column not in df.columns:
        raise ValueError(f"Column '{text_column}' not found in DataFrame.")

    # 1. ê³µë°± ë° NaN ê°’ ì²˜ë¦¬
    df[text_column] = df[text_column].fillna('').str.strip()

    # 2. ì´ëª¨í‹°ì½˜ ì²˜ë¦¬
    df[text_column] = df[text_column].apply(replace_emoticons)

    # 3. íŠ¹ìˆ˜ë¬¸ì ì œê±°
    df[text_column] = df[text_column].apply(remove_special_characters)

    # 4. ìëª¨ ë¶„ë¦¬ í•´ê²° ë° ì¤‘ë³µ ë¬¸ì ì •ë¦¬
    df[text_column] = df[text_column].apply(preprocess_text)

    # 5. í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¼ í•„í„°ë§ (5 ~ 300ì ì‚¬ì´)
    return df[df[text_column].apply(len).between(5, 300)]

# CSV íŒŒì¼ì—ì„œ ì¤„ë°”ê¿ˆì´ í¬í•¨ëœ ëŒ“ê¸€ ì²˜ë¦¬
def preprocess_multiline_csv(file_path, output_path=None):
    """
    Preprocess a multiline CSV file where comments span multiple lines.
    Correctly handles comments enclosed in quotes.
    """
    logging.info("Loading CSV file: %s", file_path)
    df = pd.read_csv(
        file_path,
        quotechar='"',
        escapechar="\\",
        encoding="utf-8"
    )
    logging.info("Loaded %d rows from CSV.", len(df))

    df = preprocess_dataframe(df, text_column='comment')
    logging.info("Preprocessed data: %d rows after filtering.", len(df))

    if output_path:
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        logging.info("Saved processed data to: %s", output_path)

    return df