import pandas as pd
import re
import unicodedata

def merge_feedback_with_train_data(train_data_path, feedback_data_path):
    train_data = pd.read_csv(train_data_path)
    feedback_data = pd.read_csv(feedback_data_path)
    merged_data = pd.concat([train_data, feedback_data], ignore_index=True)
    return merged_data

# ì´ëª¨í‹°ì½˜ ë§¤í•‘
EMOTICON_MAP = {
    "â¤ï¸": "ì‚¬ë‘í•´ìš”", "ğŸ§¡": "ì‚¬ë‘í•´ìš”", "ğŸ’›": "ì‚¬ë‘í•´ìš”", "ğŸ’š": "ì‚¬ë‘í•´ìš”",
    "ğŸ’™": "ì‚¬ë‘í•´ìš”", "ğŸ’": "ì‚¬ë‘í•´ìš”", "ğŸ’“": "ì‚¬ë‘í•´ìš”", "ğŸ’œ": "ì‚¬ë‘í•´ìš”",
    "â£ï¸": "ì‚¬ë‘í•´ìš”", "ğŸ’•": "ì‚¬ë‘í•´ìš”", "ğŸ’˜": "ì‚¬ë‘í•´ìš”", "ğŸ’—": "ì‚¬ë‘í•´ìš”",
    "ğŸ’": "ì‚¬ë‘í•´ìš”", "ğŸ’Ÿ": "ì‚¬ë‘í•´ìš”", "ğŸ˜»": "ì‚¬ë‘í•´ìš”", "ğŸ’”": "ì‹«ì–´í•´ìš”",
    "ğŸ‘": "ìµœê³ ì—ìš”", "ğŸ‘": "ìµœì•…ì´ì—ìš”", "ğŸ™Œ": "ë§Œì„¸", "ğŸ˜˜": "ì‚¬ë‘í•´ìš”",
    "ğŸ˜": "ì‚¬ë‘í•´ìš”", "ğŸ˜ƒ": "ì¢‹ì•„ìš”", "ğŸ˜„": "ì¢‹ì•„ìš”", "ğŸ˜": "ì¢‹ì•„ìš”",
    "ğŸ˜†": "ì¢‹ì•„ìš”", "â˜ºï¸": "ì¢‹ì•„ìš”", "ğŸ˜Š": "ì¢‹ì•„ìš”", "ğŸ˜š": "ì¢‹ì•„ìš”",
    "ğŸ¤—": "ì¢‹ì•„ìš”", "ğŸ˜­": "ìŠ¬í¼ìš”", "ğŸ˜¢": "ìŠ¬í¼ìš”", "ğŸ˜¤": "ì‚ì¡Œì–´ìš”",
    "ğŸ˜ ": "í™”ë‚¬ì–´ìš”", "ğŸ˜¡": "í™”ë‚¬ì–´ìš”", "ğŸ¤¬": "í™”ë‚¬ì–´ìš”", "ğŸ˜³": "ì˜ ëª¨ë¥´ê² ì–´ìš”",
    "ğŸ¤”": "ê³ ë¯¼í•´ ë³¼ê²Œìš”", "^^": "ì¢‹ì•„ìš”", "â™¡": "ì‚¬ë‘í•´ìš”", "â™¥": "ì‚¬ë‘í•´ìš”"
}

# ì´ëª¨í‹°ì½˜ ì²˜ë¦¬ í•¨ìˆ˜
def replace_emoticons(text):
    """
    Replace emoticons and special symbols in text with mapped expressions.
    Handles non-string types by converting them to strings.
    """
    if not isinstance(text, str):  # ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
        return str(text)  # ë¬¸ìì—´ë¡œ ë³€í™˜
    for emoticon, replacement in EMOTICON_MAP.items():
        text = text.replace(emoticon, replacement)
    return text

# íŠ¹ìˆ˜ë¬¸ì ì œê±° í•¨ìˆ˜
def remove_special_characters(text):
    """
    Remove special characters except ^^, !, ?, ., ,.
    """
    return re.sub(r'(?!\^\^)[^\w\s!?.,]', '', text)

# ìëª¨ ë¶„ë¦¬ í•´ê²° ë° ì¤‘ë³µ ë¬¸ì ì •ë¦¬ í•¨ìˆ˜
def preprocess_text(text):
    """
    Normalize text to resolve Jamo separation and reduce repeated characters.
    """
    # ìëª¨ ë¶„ë¦¬ í•´ê²°
    text = unicodedata.normalize('NFC', text)
    # ì¤‘ë³µ ë¬¸ì ì •ë¦¬ (3íšŒ ì´ìƒ ë°˜ë³µë˜ëŠ” ë¬¸ì 2íšŒë¡œ ì¶•ì†Œ)
    text = re.sub(r"(.)\1{2,}", r"\1\1", text)
    return text

# ë°ì´í„°í”„ë ˆì„ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_dataframe(df, text_column='comment'):
    """
    Preprocess a DataFrame by handling NaN, stripping whitespace, replacing emoticons,
    removing special characters, and normalizing text.
    Filters rows based on text length (5 to 300 characters).
    """
    # 1. ê³µë°± ë° NaN ê°’ ì²˜ë¦¬
    df[text_column] = df[text_column].fillna('')  # NaN ê°’ì€ ë¹ˆ ë¬¸ìì—´ë¡œ ëŒ€ì²´
    df[text_column] = df[text_column].str.strip()  # ë¬¸ìì—´ ì–‘ë ê³µë°± ì œê±°

    # 2. ì´ëª¨í‹°ì½˜ ì²˜ë¦¬
    df[text_column] = df[text_column].apply(replace_emoticons)

    # 3. íŠ¹ìˆ˜ë¬¸ì ì œê±°
    df[text_column] = df[text_column].apply(remove_special_characters)

    # 4. ìëª¨ ë¶„ë¦¬ í•´ê²° ë° ì¤‘ë³µ ë¬¸ì ì •ë¦¬
    df[text_column] = df[text_column].apply(preprocess_text)

    # 5. í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¼ í•„í„°ë§ (5 ~ 300ì ì‚¬ì´)
    df = df[df[text_column].apply(len).between(5, 300)]

    return df